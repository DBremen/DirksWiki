## Entropy {#entropy}

Based on observations of steam engines Work = Heat energy input – heat energy lost (friction, sound). No such flow exists.

Entropy -&gt; The **entropy** of an object is a measure of the amount of [energy](https://simple.wikipedia.org/wiki/Energy) which is unavailable to do [work](https://simple.wikipedia.org/wiki/Work_(physics)). Entropy is also a measure of the number of possible arrangements the atoms in a system can have. In this sense, entropy is a measure of uncertainty or [randomness](https://simple.wikipedia.org/wiki/Randomness). **The higher the entropy of an object, the more uncertain we are about the states of the atoms making up that object because there are more states to decide from.** A law of physics says that it takes work to make the entropy of an object or system smaller; without work, entropy can never become smaller – you could say that everything slowly goes to disorder (or being from more concentrated into more dispersed) (higher entropy).

Number of arrangements for identical objects (based on combinations):

Arrange 5 books in 3 shelves

n = 5 + 3 -1 = 7

r = 3 – 1 = 2

=FACT(7)/(FACT(2)*FACT(7)) or combin(7,2)

**https://aatishb.com/entropy/**

**2 farms with 3 sheep in 3 plots each. Representing to solids with 3 atoms and 3 boundaries.**

**Combin(6+6-1,6-1) = 462**

| **# sheep 1st farm** | **Count multiplier 1** | **# sheep 2nd farm** | **Count multiplier 2** | **Total** | **% of 462** |
| --- | --- | --- | --- | --- | --- |
| 0 | 1 | 6 | 28 | 28 | 6% |
| 1 | 3 | 5 | 21 | 63 | 14% |
| 2 | 6 | 4 | 15 | 90 | 19% |
| 3 | 10 | 3 | 10 | 100 | 22% |
| 4 | 15 | 2 | 6 | 90 | 19% |
| 5 | 21 | 1 | 3 | 63 | 14% |
| 6 | 28 | 0 | 1 | 28 | 6% |

Since atoms have much higher numbers of “moving parts” the likelihood of a low entropy state (skewed distribution of sheep) is very low. This is why systems tend to move towards equilibrium over time.

Example with 200 sheep and 300 plots

We learned that the entropy of our universe keeps rising, and this is because **higher entropy states are more probable than lower entropy ones**. Based on this, we can extrapolate that our universe must have started off in a very improbable state of very low entropy.

### Maxwell’s daemon: {#maxwell-s-daemon}

Only by knowing which particles are moving fast vs. slow a daemon could separate cold from hot molecules, thereby creating order from disorder only by using information and no energy. But it turns out that the daemon needs to store the information and in order to delete the information (if the storage runs out of space) it will take energy to do so.